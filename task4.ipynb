{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f030fff0-38b4-4cc9-88aa-d8cd09a0dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d2f0ea3d-0228-4e8b-9a5d-e081341bbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4f1e91f3-cafd-45a5-9bed-614be9b93629",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "831c01e3",
   "metadata": {},
   "source": [
    "##### Let's start with some preparations. Code below is not perfect but it does its job :)\n",
    "In case that is may be hard to read, i left here some actions that i did to prepare data:\n",
    "- remove `/t`,\n",
    "- remove url link, \n",
    "- replace accented symbols with non-accented one,\n",
    "- remove all special symbols,\n",
    "- remove stopwords (both russian and english),\n",
    "- remove extra spaces,\n",
    "- remove single letters,\n",
    "- remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8b23eb84-482e-49b6-b4d1-ce88b3a70f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eaec19ec-1327-4f6d-aec8-411e792d6efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "|http://ru.wikiped...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"encoding\", \"utf-8\").text(\"wiki.txt\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b42061ae-7359-469e-8451-18d14294519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('value', regexp_replace('value', '\\t', ' '))\n",
    "df = df.withColumn('value', regexp_replace('value', r'http\\S+', ''))\n",
    "df = df.withColumn('value', regexp_replace('value', 'а́', 'а'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'я́', 'я'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'у́', 'у'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'ю́', 'ю'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'о́', 'о'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'е́', 'е'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'ё', 'е'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'э́', 'э'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'и́', 'и'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'ы́', 'ы'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'А́', 'А'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'Я́', 'Я'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'У́', 'У'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'Ю́', 'Ю'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'О́', 'О'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'Е́', 'Е'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'Ё', 'Е'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'Э́', 'Э'))\n",
    "df = df.withColumn('value', regexp_replace('value', 'И́', 'И'))\n",
    "df = df.withColumn('value', regexp_replace('value', r'[^A-Za-zА-яа-я]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "180ab703-318d-409c-b206-ab188e4b422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "nltk.download('stopwords')\n",
    "rus_stopwords = set(stopwords.words('russian'))\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "STOPWORDS = rus_stopwords.union(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "eda0241a-465c-4635-9f2c-a4d9cd2d2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_stopwords_and_spaces(text: str) -> str:\n",
    "    clear_sentence = ' '.join([word for word in text.split() if word.lower() not in STOPWORDS])\n",
    "    clear_sentence = re.sub('\\\\s+', ' ', clear_sentence)\n",
    "    return clear_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "350f9469-e57e-4ba5-84ae-2959433578c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_and_spaces = udf(lambda s: _remove_stopwords_and_spaces(s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d30fade9-c33a-4c68-9a40-08dfeea0f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('value', remove_stopwords_and_spaces(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1b46dda9-021d-419a-afe2-693722bd67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_single_letters(text: str) -> str:\n",
    "    return re.sub('(\\\\b[A-Za-zА-яа-я] \\\\b|\\\\b [A-Za-zА-яа-я]\\\\b)', '', text)\n",
    "    \n",
    "convert_remove_single_letters_UDF = udf(lambda s: _remove_single_letters(s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce8e9ca3-4baa-42e5-9ffc-86f8f5f1ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('value', convert_remove_single_letters_UDF(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "12515f4e-d936-4104-b0fe-e41715ba3c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12601"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f2c99ac4-d131-492f-956b-58cbf3e4df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.value != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f387658a-b84f-4f5c-b69f-c77d45a1028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f7feb7f0-a778-49f2-9729-e2f996370137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed51eaa2",
   "metadata": {},
   "source": [
    "##### We are done with some preparations. I believe it could be done better, but...) Here comes task 4.1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9ebae8ab-0763-41cb-bfb9-7aae68c404a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fca487c0-0062-4533-9bc6-d807c643df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_longest_per_row = rdd.map(lambda row: builtins.max(row[0].split(), key=len)).max(key=len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "697f440f-268d-4a3f-aa2c-3a7c10c83c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longiest word is 'dreihundertvierundsechzigtausendachthundertneunzehn'\n"
     ]
    }
   ],
   "source": [
    "print(f\"The longiest word is '{rdd_longest_per_row}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6b32fc0",
   "metadata": {},
   "source": [
    "##### Here comes task 4.2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4fcb8ba7-d22c-451d-9cd9-b79ea834576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_sum_and_amount(text: str) -> Tuple[int, int]:\n",
    "    only_symbols = len(re.sub('[\\W_]+', '', text))\n",
    "    amount = len(re.findall(r'\\w+', text))\n",
    "    return only_symbols, amount\n",
    "\n",
    "def add_tuples(t1: Tuple[int, int], t2: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    return (t1[0] + t2[0], t1[1] + t2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c3c27f81-cfbe-434e-bbff-ef9a54dc211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sum_and_amount = rdd.map(lambda row: count_words_sum_and_amount(row[0])).reduce(add_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4a137f2b-6189-4ac2-afb5-5eeedd05d124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of word is 7.70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean length of word is {(words_sum_and_amount[0]/words_sum_and_amount[1]):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38a0d8a8",
   "metadata": {},
   "source": [
    "##### Here comes task 4.3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "74032595-d5dc-462f-9571-9667dc05030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_except_en(text: str) -> str:\n",
    "    text = re.sub(r'[^a-zA-Z ]+', '', text)\n",
    "    text = re.sub('\\\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c3206549-8d74-4e31-af75-fc17d55876cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3b7cbd9d-89fe-48e5-9d8b-76cc45c6262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_rdd = rdd.map(lambda row: remove_except_en(row[0])).map(lambda row: Counter(row.split())).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2c089671-8e82-47a6-8fd0-b3ce60bca49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common latin letters word is 'formula', it was met 11605 times.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Most common latin letters word is '{en_rdd.most_common(1)[0][0]}', it was met {en_rdd.most_common(1)[0][1]} times.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42e5f233",
   "metadata": {},
   "source": [
    "##### Here comes task 4.4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3e1cad6d-243b-4e43-9df5-4882406abfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rdd = rdd.flatMap(lambda row: row[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c067462f-eea1-4c66-9236-0e4f0773e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_rdd = words_rdd.filter(lambda word: word[0].isupper() and word[1:].islower()).map(lambda word: word.lower()).map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "94db6c6d-319c-4aa7-abf7-dde321df462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_rdd = words_rdd.filter(lambda word: word.islower()).map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8ee4dc60-f3e7-4695-b8c9-42f264fa9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_rdd = capital_rdd.reduceByKey(lambda a,b:a+b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c33f3d28-a534-4690-942a-2bb0cace2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_rdd = capital_rdd.filter(lambda word: word[1] > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "62588991-88f6-463e-8098-56e8b0dc0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_rdd = lower_rdd.reduceByKey(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b553a191-6de4-4855-a50f-bc48a9c96ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = capital_rdd.join(lower_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "21bd1f75-7f44-44fd-b43a-6b74470a96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = joined.filter(lambda word: (word[1][0] / (word[1][0] + word[1][1])) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dbb34060-09df-4872-a2e4-fc381b4e1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = joined.sortBy(lambda word: word[1][0], ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9f2bb3fd-1f4f-4bf2-809a-bc4466d23319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see first the most popular capital case in original doc words:\n",
      "[('однако', (5349, 4428)), ('см', (3711, 2451)), ('категория', (3505, 82)), ('российской', (2820, 471)), ('кроме', (2729, 1460)), ('согласно', (2315, 1770)), ('германии', (2214, 2)), ('федерации', (1965, 231)), ('франции', (1685, 1)), ('республики', (1631, 1149))]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Let's see first the most popular capital case in original doc words:\\n{coll[:10]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1883ce5",
   "metadata": {},
   "source": [
    "##### Here comes task 4.5!\n",
    "Lets come back to unprepared data and do some simplier preparations: just remove extra spaces, stopwords and rm accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b8a5af21-a0de-4b33-a277-befbf2f9453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"encoding\", \"utf-8\").text(\"wiki.txt\")\n",
    "df = df.withColumn('value', regexp_replace('value', '\\t', ' '))\n",
    "df = df.withColumn('value', regexp_replace('value', r'http\\S+', ''))\n",
    "df = df.withColumn('value', remove_stopwords_and_spaces(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d07fb9b7-3969-4106-a806-46e8ec976b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "976666de-1f06-4d8f-b237-1acf31a18847",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?:\\s[а-я][а-я]\\.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e54cfdb9-af5a-4bc9-900f-b74caac6132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_cuts_by_regex(pattern: str, text: str) -> Counter:\n",
    "    cuts = re.findall(pattern, text)\n",
    "    return Counter(cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5553274d-0866-4e00-9e77-c0eae1821a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_cuts = rdd.filter(lambda word: re.search(pattern, word[0]) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a94668a3-6993-4e45-a04f-996ccc74f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_cuts = rdd.map(lambda word: _find_cuts_by_regex(pattern, word[0])).reduce(add)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de1123ef",
   "metadata": {},
   "source": [
    "Let's assume that we count only words met 50 or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4e45c633-9992-4ae9-9552-43b97aead79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_cuts = Counter({k: c for k, c in rdd_cuts.items() if c >= 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "386bbff0-f142-47a9-8b6d-797a324a3058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({' др.': 2406,\n",
       "         ' гг.': 2345,\n",
       "         ' км.': 1253,\n",
       "         ' им.': 916,\n",
       "         ' вв.': 661,\n",
       "         ' см.': 488,\n",
       "         ' ст.': 417,\n",
       "         ' мм.': 345,\n",
       "         ' ул.': 326,\n",
       "         ' св.': 316,\n",
       "         ' кв.': 249,\n",
       "         ' пр.': 225,\n",
       "         ' ок.': 208,\n",
       "         ' га.': 198,\n",
       "         ' их.': 158,\n",
       "         ' кг.': 150,\n",
       "         ' мг.': 86,\n",
       "         ' ед.': 83,\n",
       "         ' ср.': 80,\n",
       "         ' мл.': 56,\n",
       "         ' юг.': 52,\n",
       "         ' шт.': 51})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_cuts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0359a3f5",
   "metadata": {},
   "source": [
    "##### Here comes task 4.6!\n",
    "similar to the task 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cefc09fa-f6a3-4cf9-b8d5-5c22875e48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(?:[а-я]\\.[а-я]\\.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7d252c60-0d04-45eb-865d-88b16f486bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"encoding\", \"utf-8\").text(\"wiki.txt\")\n",
    "df = df.withColumn('value', regexp_replace('value', '\\t', ' '))\n",
    "df = df.withColumn('value', regexp_replace('value', r'http\\S+', ''))\n",
    "df = df.withColumn('value', convertUDF(\"value\"))\n",
    "rdd = df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ccd6c081-6313-4293-9604-e8ab454f021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_cuts = rdd.filter(lambda word: re.search(pattern, word[0]) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a9923b74-6ddf-4b17-84dd-1aa5f179dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_cuts = rdd.map(lambda word: _find_cuts_by_regex(pattern, word[0])).reduce(add)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40820e23",
   "metadata": {},
   "source": [
    "Let's assume that we count only words met 4 or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5a634b9b-46c8-435a-8a61-b73d9c69f5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'т.е.': 88,\n",
       "         'н.э.': 82,\n",
       "         'т.д.': 80,\n",
       "         'г.р.': 45,\n",
       "         'ю.ш.': 41,\n",
       "         'л.с.': 36,\n",
       "         'т.п.': 35,\n",
       "         'в.м.': 32,\n",
       "         'с.ш.': 30,\n",
       "         'т.н.': 30,\n",
       "         'т.к.': 27,\n",
       "         'г.г.': 20,\n",
       "         'д.ч.': 17,\n",
       "         'т.ч.': 17,\n",
       "         'в.д.': 13,\n",
       "         'н.ч.': 13,\n",
       "         'э.д.': 11,\n",
       "         'р.п.': 10,\n",
       "         'в.в.': 9,\n",
       "         'и.т.': 8,\n",
       "         'с.т.': 7,\n",
       "         'д.н.': 6,\n",
       "         'д.и.': 5,\n",
       "         'т.о.': 5,\n",
       "         'а.е.': 5,\n",
       "         'м.р.': 5,\n",
       "         'и.о.': 5,\n",
       "         'д.м.': 5,\n",
       "         'с.п.': 5,\n",
       "         'р.з.': 4,\n",
       "         'ж.р.': 4,\n",
       "         'ж.д.': 4,\n",
       "         'б.м.': 4,\n",
       "         'п.п.': 4})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_cuts = Counter({k: c for k, c in rdd_cuts.items() if c >= 4})\n",
    "rdd_cuts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f301a34",
   "metadata": {},
   "source": [
    "As you may see, we get some outliers such as  `их.` in task 4.5 or `а.е` in task 4.6. \n",
    "\n",
    "There is two options: \n",
    "- we can change threshold to larger value and lose some valuable results such as `ж.р` or `кг.`\n",
    "- we may exclude outliers manually\n",
    "- or use look-up table for abbreviations instead of statistic :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404edcb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
